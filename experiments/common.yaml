dataset:
    sequence_len: 256
    batch_size: 64
    alphabet_size: 16
    mem_tokens: 16
    selective: False

trainer:
    steps: 100000
    test_steps: 10
    optimizer_class: torch.optim.AdamW
    optimizer_params:
        lr: 0.0001
    device: "cuda"

logger:
    logging_steps: 100
    enable_progress_bar: False

model:
  input_dim: 16
  hid_dim: 64
  model_dim: 64
  output_dim: 16
  n_layers: 2